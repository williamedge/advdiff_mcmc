{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e04fc982",
   "metadata": {},
   "source": [
    "# Notebook for Edge et al. (2022) JGR:JAMES submission\n",
    "\n",
    "## Case Study 1: Erosion model 1\n",
    "\n",
    "Notes:\n",
    "- This Case Study does not require an advection-diffusion model, but the function has been kept constant across all case studies.\n",
    "- This version of the notebook was not run in an optimized Python environment (g++, chain parallelization). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc024799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pymc3 as pm\n",
    "import arviz as az\n",
    "import seaborn as sns\n",
    "import theano.tensor as tt\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from edge_funcs import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "sns.set_style(\"ticks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae49b67",
   "metadata": {},
   "source": [
    "### Load forcing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b629ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_shear = pd.read_csv('Bed_stress.csv', names=['x','y'])\n",
    "csv_shear.sort_values(by=['x'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a0422c",
   "metadata": {},
   "source": [
    "## Create the grid\n",
    "\n",
    "Then create the forcing data for the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa31ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "del_z = 0.025 # metres\n",
    "del_t = 60.0 # seconds\n",
    "\n",
    "h_tot = 0.1\n",
    "f_wid = 0.15\n",
    "len_tot = csv_shear['x'].iloc[-1]*60\n",
    "\n",
    "fg, mg, tg = generate_grid(h_tot, del_z, len_tot, del_t)\n",
    "\n",
    "print('Grid size: ' + str(len(tg)) + ' x ' + str(len(mg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b71592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate bed shear stress onto time grid\n",
    "mod_fi = interp1d(csv_shear['x'], csv_shear['y'], bounds_error=False, fill_value='extrapolate')\n",
    "tau_bed_tg = mod_fi(tg/60)\n",
    "tau_bed_tg[tau_bed_tg<0] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc2ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diffusivity data for the time-space grid (not required for this case study)\n",
    "km_bg = 0\n",
    "K_alpha = 1\n",
    "\n",
    "Ks_all = calc_Ks(np.sqrt(tau_bed_tg/1020), fg, np.repeat(h_tot, len(tg)), km_bg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedd702",
   "metadata": {},
   "source": [
    "### Load the fitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f52d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv_conc = pd.read_csv('SSC.csv', names=['x','y'])\n",
    "\n",
    "# Interpolate sediment concentration onto time grid\n",
    "mod_fi = interp1d(csv_conc['x'], csv_conc['y'], bounds_error=False, fill_value=np.nan, kind='nearest')\n",
    "conc_tg = mod_fi(tg/60)\n",
    "conc_tg[np.isnan(conc_tg)] = conc_tg[~np.isnan(conc_tg)][0]\n",
    "\n",
    "# Change from depth-averaged to mass concentration using height of flume\n",
    "conc_tg = conc_tg / h_tot\n",
    "\n",
    "# Finally remove initial concentration (background SSC)\n",
    "forcing_obs = (conc_tg - conc_tg[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the steady state indexes for the end of each step (used for analysis in original paper)\n",
    "bs_tc = np.array([27, 56, 90, 120, 147, 210, 265, 325, 390, 448, 495])/2\n",
    "bs_tc = bs_tc.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fd1e7f",
   "metadata": {},
   "source": [
    "# Plot forcing and fitting data\n",
    "\n",
    "Plotting C with background value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51070522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5.5,5.5), constrained_layout=False)\n",
    "\n",
    "p1=sns.scatterplot(x=tg/60, y=tau_bed_tg, s=10, color='0.', label=r'$\\tau_{bed}$', legend=False)\n",
    "p4=sns.scatterplot(x=tg[bs_tc]/60, y=tau_bed_tg[bs_tc], ax=ax, s=60, zorder=3,\\\n",
    "                   label=r'$\\widehat{\\tau}_{bed}$', legend=False)\n",
    "\n",
    "par=ax.twinx()\n",
    "p2=sns.scatterplot(x=tg/60, y=conc_tg, ax=par, s=14,\\\n",
    "                   color=sns.color_palette(\"husl\", 9)[1], zorder=1, label=r'$\\overline{C}$', legend=False)\n",
    "p3=sns.scatterplot(x=tg[bs_tc]/60, y=(conc_tg)[bs_tc], ax=par, s=60,\\\n",
    "                   color=sns.color_palette()[3], zorder=2, label=r'$\\widehat{C}$', legend=False)\n",
    "\n",
    "ax.set_ylabel(r'$\\tau_{bed}$ [Pa]')\n",
    "par.set_ylabel(r'$\\overline{C}$ [kg m$^{-3}$]')\n",
    "ax.set_xlabel('Minutes')\n",
    "ax.set_title('Sanford & Maa (2001, Figure 1b)')\n",
    "\n",
    "ax.set_ylim(0, 0.4)\n",
    "ax.set_yticks(np.arange(0, 0.5, 0.1))\n",
    "ax.set_xlim((tg/60)[0], (tg/60)[-1])\n",
    "par.set_ylim(0, 4.0)\n",
    "par.set_yticks(np.arange(0, 4.01, 1.0))\n",
    "\n",
    "handles,labels = [],[]\n",
    "for ax in fig.axes:\n",
    "    for h,l in zip(*ax.get_legend_handles_labels()):\n",
    "        handles.append(h)\n",
    "        labels.append(l)\n",
    "\n",
    "plt.legend(handles,labels, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75474d9",
   "metadata": {},
   "source": [
    "# Run the inference\n",
    "\n",
    "See edge_funcs.py for numerical model code, log-likelihood function, and related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3fdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the initial concentration profile (zeros for CS1)\n",
    "cn_rn = np.full_like(mg, conc_tg[0]/len(mg))\n",
    "cn_rn = np.zeros_like(mg)\n",
    "\n",
    "model_spec = [tg, mg, fg, cn_rn, Ks_all, h_tot, tau_bed_tg]\n",
    "obs_htx = np.full(len(mg), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bfd21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create operation, specify erosion model (E1 or E2)\n",
    "logl = LogLike(my_loglike_mean, forcing_obs, 'E1', model_spec ,obs_htx, False)\n",
    "\n",
    "# create model and set priors\n",
    "with pm.Model() as model:\n",
    "    w_s_pdf = pm.Lognormal('w_s', mu=0.5, sigma=0.7)\n",
    "    e_0_pdf = pm.HalfNormal('e_0', sd=20)\n",
    "    t_c_pdf = pm.HalfNormal('t_c', sd=3)\n",
    "    m_c_pdf = 0.0\n",
    "    b_c_pdf = pm.Lognormal('b_c', mu=0.25, sigma=0.5)\n",
    "    sig_pdf = pm.HalfNormal('sig_mod', 3.0)\n",
    "\n",
    "    # Convert parameters to a tensor vector\n",
    "    theta = tt.as_tensor_variable([w_s_pdf, e_0_pdf, t_c_pdf, m_c_pdf, b_c_pdf, sig_pdf])\n",
    "    \n",
    "    # Specify custom log-likelihood (standard Guassian that takes numerical model output - see edge_funcs.py)\n",
    "    likelihood = pm.DensityDist(\"likelihood\", lambda v: logl(v), observed={\"v\": theta})\n",
    "    \n",
    "    # Save log-likelihood value (extra step - increases run time)\n",
    "    llk = pm.Deterministic('logp', model.logpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e747d",
   "metadata": {},
   "source": [
    "# Run the inference \n",
    "\n",
    "Save when complete so it can be re-loaded quickly for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200d03a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with model:\n",
    "    trace_norm = pm.sample(20000, step=pm.DEMetropolis(), chains=12, tune=10000,\\\n",
    "                           pickle_backend='dill', cores=1, compute_convergence_checks=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1869a997",
   "metadata": {},
   "source": [
    "Remove burn-in samples and save trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_all = az.from_pymc3(trace_norm, density_dist_obs=False, log_likelihood=False)\n",
    "i_xr = az.convert_to_dataset(id_all)\n",
    "i_xr_result = i_xr.isel(draw=np.arange(10000,30000)))\n",
    "i_xr_result.to_netcdf(path='CS1_E2', mode='w')\n",
    "print('Trace saved')\n",
    "\n",
    "i_xr_result = xr.open_dataset('CS1_E1', engine='netcdf4', mode='r')\n",
    "print('Trace loaded') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=az.plot_trace(i_xr_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.stats.summary(i_xr_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to dataframe for plotting with seaborn\n",
    "df = i_xr_result.to_dataframe()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Force correct order\n",
    "dcols = ['w_s', 'e_0', 't_c', 'm_c', 'b_c', 'sig_mod']\n",
    "df = df[dcols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef93552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples from priors for plotting\n",
    "w_s_prior = w_s_pdf.random(size=len(df))\n",
    "t_c_prior = t_c_pdf.random(size=len(df))\n",
    "e_0_prior = e_0_pdf.random(size=len(df))\n",
    "b_c_prior = b_c_pdf.random(size=len(df))\n",
    "m_c_prior = m_c_pdf.random(size=len(df))\n",
    "sig_prior = sig_pdf.random(size=len(df))\n",
    "\n",
    "df_prior = pd.DataFrame({'w_s':w_s_prior, 'e_0':e_0_prior, 't_c':t_c_prior, \\\n",
    "                         'm_c':m_c_prior, 'b_c':b_c_prior, 'sig':sig_prior})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c56fa7",
   "metadata": {},
   "source": [
    "### Plot posteriors (with priors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 6, figsize=(10,2), constrained_layout=False)\n",
    "\n",
    "labs = ['$w_s \\\\times 10^{-4}$\\n[m s$^{-1}$]', '$M \\\\times 10^{-3}$\\n[kg m$^{-2}$ s$^{-1}$]',\\\n",
    "        '$\\\\tau_{cr0} \\\\times 10^{-3}$\\n[Pa]', '$\\\\tau_m \\\\times 10^{-1}$\\n[Pa $m_c^{-\\\\tau_b}$]',\\\n",
    "        '$\\\\tau_b \\\\times 10^{-1}$', '$\\\\sigma \\\\times 10^{-2}$\\n[kg m$^{-3}$]']\n",
    "\n",
    "plt_scaling = [1,0.1,10,1,10,1]\n",
    "\n",
    "for (x, dpri, dpos, lbs, ps) in zip(ax, df_prior, df, labs, plt_scaling):\n",
    "    df_p = df_prior[dpri]*ps\n",
    "    df_s = df[dpos]*ps\n",
    "    sns.kdeplot(df_p, ax=x, fill=True,\\\n",
    "                color=sns.color_palette(\"deep\", 10)[7], cut=0)\n",
    "    sns.kdeplot(df_s, ax=x, fill=True, bw_adjust=2.0,\\\n",
    "                color=sns.color_palette(\"deep\", 10)[0], cut=0)\n",
    "\n",
    "    ldt = sns.kdeplot(df_s, alpha=0, ax=x, bw_adjust=2.0,\\\n",
    "                        cut=0).get_lines()[0].get_data()\n",
    "    \n",
    "    ax_med = np.median(df_s)\n",
    "    ax_025 = np.percentile(df_s, 2.5)\n",
    "    ax_975 = np.percentile(df_s, 97.5)\n",
    "    \n",
    "    ax_med_ix = np.argmin(np.abs(ax_med - ldt[0]))\n",
    "    ax_025_ix = np.argmin(np.abs(ax_025 - ldt[0]))\n",
    "    ax_975_ix = np.argmin(np.abs(ax_975 - ldt[0]))\n",
    "    ax_plt = [ax_025_ix, ax_med_ix, ax_975_ix]\n",
    "    \n",
    "    sns.scatterplot(x=ldt[0][ax_plt], y=ldt[1][ax_plt], ax=x,\\\n",
    "                    facecolor='w',\\\n",
    "                    edgecolor=sns.color_palette(\"deep\", 10)[0],\\\n",
    "                    size=8, linewidth=1, legend=False)\n",
    "    if x==ax[1]:\n",
    "        x.set_title(str(np.round(ax_med, 1)) + ' (' + str(np.round(ax_025, 1)) + ', ' +\\\n",
    "                    str(np.round(ax_975, 1)) + ')')\n",
    "    else:\n",
    "        x.set_title(str(np.round(ax_med, 2)) + ' (' + str(np.round(ax_025, 2)) + ', ' +\\\n",
    "                    str(np.round(ax_975, 2)) + ')')\n",
    "        \n",
    "    x.set_xlabel(lbs)\n",
    "\n",
    "    x.spines['right'].set_visible(False)\n",
    "    x.spines['left'].set_visible(False)\n",
    "    x.spines['top'].set_visible(False)\n",
    "\n",
    "    x.tick_params(axis='y', which='both', left=False, right=False, labelleft=False)\n",
    "    if x != ax[0]:\n",
    "        x.set_ylabel('')\n",
    "ax[0].set_xlim(0,6.5)\n",
    "ax[1].set_xlim(3.0 ,4.47)\n",
    "ax[2].set_xlim(-0.8,20)\n",
    "ax[3].set_xlim(5.6,5.8)\n",
    "ax[4].set_xlim(4.15,4.7)\n",
    "ax[5].set_xlim(5.5,9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aabeb5f",
   "metadata": {},
   "source": [
    "## Generate posterior predictive samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf7e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samp = 10000 # 10,000 for paper\n",
    "trace_len = len(df)\n",
    "rand_init = np.random.randint(0, trace_len, (n_samp))\n",
    "samp_res = np.full((n_samp, len(tg)), np.nan)\n",
    "samp_noi = np.full((n_samp, len(tg)), np.nan)\n",
    "\n",
    "for ix, ri in enumerate(rand_init):\n",
    "    theta_pred = [df['w_s'][ri], df['e_0'][ri], df['t_c'][ri], df['m_c'][ri], df['b_c'][ri]]\n",
    "    samp_res[ix,:] = np.mean(obj(theta_pred, 'E2', model_spec), axis=1)\n",
    "    \n",
    "    # Scale sigma same as log-likelihood (/100)\n",
    "    samp_noi[ix,:] = np.random.normal(loc=0, \\\n",
    "                                      scale=df['sig_mod'][ri]/100,\\\n",
    "                                      size=(len(tg),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d243f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_CI05 = np.percentile(samp_res, 2.5, axis=0)\n",
    "res_CI95 = np.percentile(samp_res, 97.5, axis=0)\n",
    "\n",
    "noi_CI16 = np.percentile(samp_res + samp_noi, 25, axis=0)\n",
    "noi_CI84 = np.percentile(samp_res + samp_noi, 75, axis=0)\n",
    "\n",
    "noi_CI05 = np.percentile(samp_res + samp_noi, 10, axis=0)\n",
    "noi_CI95 = np.percentile(samp_res + samp_noi, 90, axis=0)\n",
    "\n",
    "noi_CI01 = np.percentile(samp_res + samp_noi, 2.5, axis=0)\n",
    "noi_CI99 = np.percentile(samp_res + samp_noi, 97.5, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb64fb40",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(11.5,5.0), constrained_layout=False)\n",
    "\n",
    "gs1 = GridSpec(1, 1, figure=fig, right=0.45)\n",
    "gs2 = GridSpec(2, 2, figure=fig, left=0.53, wspace=0.46, hspace=0.07)\n",
    "\n",
    "ax = np.empty((4,), dtype='object')\n",
    "\n",
    "ax[0] = fig.add_subplot(gs1[:,:])\n",
    "\n",
    "ax[3] = fig.add_subplot(gs2[1,1])\n",
    "ax[1] = fig.add_subplot(gs2[0,0])\n",
    "ax[2] = fig.add_subplot(gs2[1,0])\n",
    "\n",
    "p2=sns.scatterplot(x=tg/60, y=conc_tg, ax=ax[0], s=14,\\\n",
    "                   color=sns.color_palette(\"husl\", 9)[1], zorder=4, label=r'$C$', legend=False)\n",
    "p3=sns.scatterplot(x=tg[bs_tc]/60, y=(conc_tg)[bs_tc], ax=ax[0], s=60,\\\n",
    "                   color=sns.color_palette()[3], zorder=5, label=r'$\\widehat{C}$', legend=False)\n",
    "\n",
    "ax[0].fill_between(tg/60, (noi_CI16 + (conc_tg)[0]),\\\n",
    "                 y2=(noi_CI84 + (conc_tg)[0]), color='dimgrey', zorder=3)\n",
    "ax[0].fill_between(tg/60, (noi_CI05 + (conc_tg)[0]),\\\n",
    "                 y2=(noi_CI95 + (conc_tg)[0]), color='darkgrey', zorder=2)\n",
    "ax[0].fill_between(tg/60, (noi_CI01 + (conc_tg)[0]),\\\n",
    "                 y2=(noi_CI99 + (conc_tg)[0]), color='gainsboro', zorder=1)\n",
    "\n",
    "# ax.set_ylabel(r'$\\tau_b$ [Pa]')\n",
    "ax[0].set_ylabel(r'$\\overline{C}$ [kg m$^{-3}$]')\n",
    "ax[0].set_xlabel('Minutes')\n",
    "ax[0].set_title('Sanford & Maa (2001, Figure 1b)')\n",
    "\n",
    "# ax[0].set_ylim(0, 0.4)\n",
    "# ax[0].set_yticks(np.arange(0, 0.5, 0.1))\n",
    "ax[0].set_xlim((tg/60)[0], (tg/60)[-1])\n",
    "ax[0].set_ylim(0, 4.10)\n",
    "ax[0].set_yticks(np.arange(0,4.10, 1))\n",
    "\n",
    "sns.scatterplot(x=df['t_c'], y=df['m_c'], ax=ax[1], s=5)\n",
    "# sns.kdeplot(x=df['t_c'], y=df['m_c'], ax=ax[1], levels=[0.05, 0.2 ,0.5],\\\n",
    "#             cut=0, bw_adjust=1.5, color='k')\n",
    "\n",
    "sns.scatterplot(x=df['t_c'], y=df['b_c'], ax=ax[2], s=5)\n",
    "# sns.kdeplot(x=df['t_c'], y=df['b_c'], ax=ax[2], levels=[0.05, 0.2 ,0.5],\\\n",
    "#             cut=0, bw_adjust=1.5, color='k')\n",
    "\n",
    "sns.scatterplot(x=df['m_c'], y=df['e_0'], ax=ax[3], s=5)\n",
    "# sns.kdeplot(x=df['m_c'], y=df['e_0'], ax=ax[3], levels=[0.05, 0.2 ,0.5],\\\n",
    "#             cut=0, bw_adjust=1.5, color='k')\n",
    "\n",
    "for x in ax[1:]:\n",
    "    x.spines['right'].set_visible(False)\n",
    "    x.spines['top'].set_visible(False)\n",
    "    \n",
    "ax[1].set_xlabel('')\n",
    "ax[1].set_xticklabels('')\n",
    "ax[1].set_ylabel(r'$\\tau_m \\times 10^{-1}$')\n",
    "\n",
    "ax[2].set_ylabel(r'$\\tau_b \\times 10^{-1}$')\n",
    "ax[2].set_xlabel(r'$\\tau_{cr0} \\times 10^{-3}$')\n",
    "\n",
    "ax[3].set_ylabel('$M \\\\times 10^{-3}$')\n",
    "ax[3].set_xlabel(r'$\\tau_m \\times 10^{-1}$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1fbf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to html Sanford_2001_V1a.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
